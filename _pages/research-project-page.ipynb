{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0109b0c5-cef3-4628-bc60-f63e598c99e5",
   "metadata": {},
   "source": [
    "# Consumer Expenditure Trends 2006-2020 \n",
    "## Ben Warzel\n",
    "### 5/8/2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78845e1-915d-45ff-996a-0ad1055d13d0",
   "metadata": {},
   "source": [
    "*Note: generative AI was used in this project to assist in data analysis*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd28454e-b64e-457b-8893-350ceae8bea5",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "The period of 2007-2010 in American Economics is referred to as the 'Great Recession'. Following a collapse of the American housing 'bubble' or ideal economic balance in the housing market, and a crisis caused by banks giving too many loans to too many people, the general household wealth and value fell dramatically.\n",
    "\n",
    "According to the Bureau of Labor Statistics, by 2005 consumers were spending 97% of their income. During the Great Recession, that number dropped to 92% due to higher mortage debt and lower home equity. People had to try to save more of their money, and the credit available to them shrank [2010 IMF Report]. The BLS also has data on employment statistics for the same time period, which we will examine later, but essentially all areas of employment saw a decrease in the workforce after the Great Recession. \n",
    "\n",
    "I chose this particular set of consumer expenditure data because it covers the majority of my childhood and adolescence, and I was curious to see the impacts of events like the 2008 housing crisis on the average American's spending habits. The rise and prevalence of credit cards into the 2010s is something else that might affect how people spend, although the credit limits were not as high then as they are now.  \n",
    "\n",
    "The main categories I chose to focus on here are Housing, Healthcare, Food, and Transportation. I also attempt to answer questions about extraneous spending; how the consumption of alcohol and tobacco changes over time for example, or the section labeled \"Entertainment\" which includes things like going to movies or concerts. We would assume that as the housing market struggled, people began spending less on non-essential items. Generally we can see this pattern represented in the data and charts, but there is another expenditure that rises sharply in the late 2010s and into the 2020s: Education. This is another area of spending that lends itself to a growing Savings account; as most households will be saving to send their children to college if they are not still paying off their own student loans. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776c4db6-ca23-48df-9605-207efcbe52a7",
   "metadata": {},
   "source": [
    "### Methods\n",
    "The original datasets were obtained from the BLS website, where I was able to download documents containing detailed line-by-line breakdowns of spending by year. These data sets were made up of information collected from voluntary Interview Surveys detailing larger expenditures and Diary Surveys which kept track of smaller weekly spending. There is demographic information provided as well, in the form of \"Percent Distribution\" (or relative total frequency out of 100) for gender and race. I believe this is an attempt to provide further context for the data, but the demographics end up being mainly White men and women. \n",
    "\n",
    "I chose to select only the documents containing information from 2006-2012 and 2013-2020. These sheets were loosely formatted with a larger section (\"Food\") contianing some amount of rows beneath it with more specific items like \"Meat\", which could also contain subsets like \"Pork\". \n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    src=\"../assets/img/sampleraw.png\"\n",
    "    width=\"60%\"\n",
    "    style=\"border: 2px solid\"\n",
    "    alt=\"Raw sample of expenditure sheet\"\n",
    "  />\n",
    "  <figcaption style=\"font-style: italic\">\n",
    "    Unrefined dataset.\n",
    "  </figcaption>\n",
    "</div>\n",
    "\n",
    "I decided that for my purposes I was not interested in the particulars of the spending, just the bigger picture. Because of this my first step was to clean the datasets to contain only the most important information. To do this, I first manually edited the sheets to remove non-monetary data. This included things like \"Average number in consumer unit\" (meaning household size) or the percent distribution of various demographic information of the reference individual. This information may be interesting but it will not serve a dataset that we want to manipulate in Python. After doing this, I took my version of the dataset and began working with Claude AI to further clean and organize the data. I instructed it to look for the Items at the beginning of a row break, as each main section is separated this way, and only include that first term.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1be16adc-3555-4b88-940f-6c1c2bd0f248",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to process the data and group by categories\n",
    "def process_consumer_spending(df):\n",
    "    # Forward fill NaN values in first column to identify categories\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].fillna('')\n",
    "    \n",
    "    # Initialize variables\n",
    "    categories = []\n",
    "    current_category = None\n",
    "    grouped_data = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        item = row.iloc[0]\n",
    "        \n",
    "        # Skip completely empty rows\n",
    "        if item == '':\n",
    "            current_category = None\n",
    "            continue\n",
    "        \n",
    "        # Check if this is a main category (no indentation and not a subcategory)\n",
    "        if not item.startswith(' ') and ',' not in item and ':' not in item:\n",
    "            # We found a new main category\n",
    "            current_category = item\n",
    "            if current_category not in categories:\n",
    "                categories.append(current_category)\n",
    "        \n",
    "        # Create a row with category information\n",
    "        new_row = row.copy()\n",
    "        if current_category:\n",
    "            new_row['Category'] = current_category\n",
    "            grouped_data.append(new_row)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    result_df = pd.DataFrame(grouped_data)\n",
    "    \n",
    "    # Clean up the monetary values\n",
    "    for year in range(2006, 2013):\n",
    "        year_col = str(year)\n",
    "        if year_col in result_df.columns:\n",
    "            result_df[year_col] = result_df[year_col].apply(lambda x: \n",
    "                pd.to_numeric(str(x).replace('$', '').replace(',', ''), errors='coerce')\n",
    "                if isinstance(x, str) else x)\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    result_df.rename(columns={result_df.columns[0]: 'Item'}, inplace=True)\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad3c4c6-63ed-4e3e-9706-bf5cc0ed8ff9",
   "metadata": {},
   "source": [
    "This worked really well and I was left with the categories:\n",
    "\n",
    "1\tAverage Annual Expenditures\n",
    "\n",
    "2\tFood\n",
    "\n",
    "3\tAlcoholic beverages\n",
    "\n",
    "4\tHousing\n",
    "\n",
    "5\tApparel and services\n",
    "\n",
    "6\tTransportation\n",
    "\n",
    "7\tHealthcare\n",
    "\n",
    "8\tEntertainment\n",
    "\n",
    "9\tPersonal care products and services\n",
    "\n",
    "10\tReading\n",
    "\n",
    "11\tEducation\n",
    "\n",
    "12\tTobacco products and smoking supplies\n",
    "\n",
    "13\tMiscellaneous\n",
    "\n",
    "14\tCash contributions\n",
    "\n",
    "15\tPersonal insurance and pensions\n",
    "\n",
    "16\tSources of income and personal taxes:\n",
    "\n",
    "17\tMoney income before taxes a/\n",
    "\n",
    "18\tPersonal taxes (missing values not imputed) a/\n",
    "\n",
    "19\tIncome after taxes a/\n",
    "\n",
    "20\tAddenda:\n",
    "\n",
    "21\tNet change in total assets and liabilities\n",
    "\n",
    "22\tOther financial information:\n",
    "\n",
    "23\tIncome before taxes\n",
    "\n",
    "24\tPersonal taxes (contains some imputed values)\n",
    "\n",
    "25\tIncome after taxes\n",
    "\n",
    "A few of these items have no data associated with them, but as far as I could tell it did not affect the computation of the results, so I decided I was okay with keeping some blank rows. \n",
    "\n",
    "After doing this for both sets of data and double checking to make sure all the categories lined up, I used Python to merge the two cleaned csv files.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ec4c6d8-e916-4fbe-8264-8c6db8ab8b45",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 36\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m main_categories_df\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Read and clean the CSV files\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m df1 \u001b[38;5;241m=\u001b[39m read_and_clean_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/original/consumer06csv.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     37\u001b[0m df2 \u001b[38;5;241m=\u001b[39m read_and_clean_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data/original/consumer13csv.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Extract main categories from each file\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[9], line 4\u001b[0m, in \u001b[0;36mread_and_clean_csv\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_and_clean_csv\u001b[39m(filename):\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Read the CSV file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(filename)\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;66;03m# Clean column names by stripping quotes and whitespace\u001b[39;00m\n\u001b[1;32m      7\u001b[0m     df\u001b[38;5;241m.\u001b[39mcolumns \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mstr\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Function to read and clean the CSV files\n",
    "def read_and_clean_csv(filename):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(filename)\n",
    "    \n",
    "    # Clean column names by stripping quotes and whitespace\n",
    "    df.columns = df.columns.str.strip('\"').str.strip()\n",
    "    \n",
    "    # For the first column, remove quotation marks and whitespace\n",
    "    df.iloc[:, 0] = df.iloc[:, 0].str.strip('\"').str.strip() if df.iloc[:, 0].dtype == 'object' else df.iloc[:, 0]\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Function to extract main categories\n",
    "def extract_main_categories(df):\n",
    "    # Identify main categories by finding rows that come right after blank rows\n",
    "    # First, identify blank rows (rows where the first column is empty or NaN)\n",
    "    blank_rows = df.iloc[:, 0].isna() | (df.iloc[:, 0] == '')\n",
    "    \n",
    "    # Find rows that come right after blank rows\n",
    "    main_category_indices = []\n",
    "    for i in range(1, len(blank_rows)):\n",
    "        if blank_rows[i-1] and not blank_rows[i]:\n",
    "            main_category_indices.append(i)\n",
    "    \n",
    "    # Also include the first row (which contains \"Average Annual Expenditure\")\n",
    "    if not blank_rows[0]:\n",
    "        main_category_indices.insert(0, 0)\n",
    "    \n",
    "    # Extract main categories and their data\n",
    "    main_categories_df = df.iloc[main_category_indices].copy()\n",
    "    \n",
    "    return main_categories_df\n",
    "\n",
    "# Read and clean the CSV files\n",
    "df1 = read_and_clean_csv('../data/original/consumer06csv.csv')\n",
    "df2 = read_and_clean_csv('../data/original/consumer13csv.csv')\n",
    "\n",
    "# Extract main categories from each file\n",
    "main_categories_df1 = extract_main_categories(df1)\n",
    "main_categories_df2 = extract_main_categories(df2)\n",
    "\n",
    "# Convert dollar values to numeric, removing $ and commas\n",
    "def clean_dollar_values(df):\n",
    "    for col in df.columns[1:]:  # Skip the first column (Item)\n",
    "        if df[col].dtype == 'object':\n",
    "            df[col] = df[col].str.replace('$', '', regex=False)\n",
    "            df[col] = df[col].str.replace(',', '', regex=False)\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df\n",
    "\n",
    "main_categories_df1 = clean_dollar_values(main_categories_df1)\n",
    "main_categories_df2 = clean_dollar_values(main_categories_df2)\n",
    "\n",
    "# Combine the two dataframes\n",
    "# First, prepare the dataframes by setting the 'Item' column as index\n",
    "main_categories_df1.set_index('Item', inplace=True)\n",
    "main_categories_df2.set_index('Item', inplace=True)\n",
    "\n",
    "# Now combine them\n",
    "combined_df = pd.concat([main_categories_df1, main_categories_df2], axis=1)\n",
    "\n",
    "# Reset index to make 'Item' a column again\n",
    "combined_df.reset_index(inplace=True)\n",
    "\n",
    "# Display the combined dataframe\n",
    "print(\"Combined data for main spending categories (2006-2020):\")\n",
    "print(combined_df)\n",
    "\n",
    "# Save the combined data to a new CSV file\n",
    "combined_df.to_csv('combined_consumer_spending_2006_2020.csv', index=False)\n",
    "print(\"\\nData saved to 'combined_consumer_spending_2006_2020.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f80b3d2-1d26-4d1d-aef8-b5839d90219f",
   "metadata": {},
   "source": [
    "Next, in order to make the dataframe a bit more readable for Python, I used the command '.long' to transform the dataframe into a \"long\" format as opposed to a \"wide\" one; meaning each item for each year is given its own row, as oppposed to four columns of years by the amount of items. Somehow this also removed the rows with no value, which was a wonderful bonus. Then I began exploring the data and looking for trends, as well as using Claude to help me examine individual items or specific areas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c9e615d-99ba-428a-9035-3ede18b398bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read the CSV file\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcombined_consumer_spending_2006_2020.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Clean up the data first by removing rows that contain summaries or non-spending categories\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# We'll keep only the main spending categories\u001b[39;00m\n\u001b[1;32m      6\u001b[0m main_categories \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAverage Annual Expenditures\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFood\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAlcoholic beverages\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHousing\u001b[39m\u001b[38;5;124m'\u001b[39m, \n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mApparel and services\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransportation\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHealthcare\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEntertainment\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCash contributions\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPersonal insurance and pensions\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     12\u001b[0m ]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Read the CSV file\n",
    "df = pd.read_csv('combined_consumer_spending_2006_2020.csv')\n",
    "\n",
    "# Clean up the data first by removing rows that contain summaries or non-spending categories\n",
    "# We'll keep only the main spending categories\n",
    "main_categories = [\n",
    "    'Average Annual Expenditures', 'Food', 'Alcoholic beverages', 'Housing', \n",
    "    'Apparel and services', 'Transportation', 'Healthcare', 'Entertainment',\n",
    "    'Personal care products and services', 'Reading', 'Education', \n",
    "    'Tobacco products and smoking supplies', 'Miscellaneous',\n",
    "    'Cash contributions', 'Personal insurance and pensions'\n",
    "]\n",
    "\n",
    "# Filter the dataframe to keep only the main spending categories\n",
    "df_clean = df[df['Item'].isin(main_categories)]\n",
    "\n",
    "# Now melt the dataframe to convert from wide to long format\n",
    "df_long = pd.melt(\n",
    "    df_clean,\n",
    "    id_vars=['Item'],  # Keep 'Item' as an identifier\n",
    "    value_vars=[str(year) for year in range(2006, 2021)],  # Years 2006-2020 as variables\n",
    "    var_name='Year',  # Name for the new column containing years\n",
    "    value_name='Spending'  # Name for the new column containing spending values\n",
    ")\n",
    "\n",
    "# Convert Year to integer and Spending to float\n",
    "df_long['Year'] = df_long['Year'].astype(int)\n",
    "df_long['Spending'] = pd.to_numeric(df_long['Spending'], errors='coerce')\n",
    "\n",
    "# Display the first few rows of the transformed data\n",
    "print(df_long.head(10))\n",
    "\n",
    "# Save the transformed data to a new CSV file\n",
    "df_long.to_csv('consumer_spending_long_format.csv', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f227332a-80ce-4c6b-bcba-d053887b98a9",
   "metadata": {},
   "source": [
    "### Main Analysis\n",
    "To begin with, there is some interesting information not contained in the graphs I created. Luckily the kind of information it is does not require in-depth processing to understand. Over all 14 years, the biggest gap between the male-female ration was 46:54 in 2006. In the following years it stayed at 47:53 into and through the 2010s with a few 48:52 seemingly at random. The distribution by race is much less balanced; almost all of the years on record here the White population representing around 87% of the reference group, with black or latino only being about 13%. \n",
    "\n",
    "Another extremely relevant statistic recorded in these documents was the percentage of homeowners surveyed who had a mortgage. The housing crisis of 2007-2008 was due to the \"bursting\" of the \"housing bubble\", essentially meaning that housing prices rose steeply and quickly which led to many more people missing payments, which in turn hurt the housing market and caused prices to plummet. Because of this, there was supposedly less desire or need for mortages. Indeed, we can see this reflected in a chart of the percentages of homeowners and renters:\n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    src=\"../assets/img/homeowners_trends.png\"\n",
    "    width=\"60%\"\n",
    "    style=\"border: 2px solid\"\n",
    "    alt=\"Homeowner Trends\"\n",
    "  />\n",
    "  <figcaption style=\"font-style: italic\">\n",
    "    Percent of Homeowners with mortage, without mortage, or renting by Year\n",
    "  </figcaption>\n",
    "</div>\n",
    "Not only does the amount of homeowners paying a mortage go down, but renters actually overtake the homeowners with mortgages in 2015. Another really interesting bit of information is that the percent of people who had completed college rose steadily from 59% in 2006 to 69% in 2020.\n",
    "\n",
    "As for the actual expenditures, I made a few broad charts showing the items with the most budget share and the percent increase or decrease each year.\n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    src=\"../assets/img/categories-budgetshare.png\"\n",
    "    width=\"60%\"\n",
    "    style=\"border: 2px solid\"\n",
    "    alt=\"Top categories\"\n",
    "  />\n",
    "  <figcaption style=\"font-style: italic\">\n",
    "    The categories with the largest budget share.\n",
    "  </figcaption>\n",
    "</div>\n",
    "\n",
    "This shows very clearly that, although the housing market took a hit after 2008, housing prices quickly began to climb again, and now we are spending more than ever before on housing. The other four categories Transportation, Apparel, Insurance, and Healthcare also show a gradual rise over the years, aside from minor dips in 2009-2010 and 2019-2020 in the Transportation and Apparel categories. \n",
    "\n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    src=\"../assets/img/percent-change.png\"\n",
    "    width=\"60%\"\n",
    "    style=\"border: 2px solid\"\n",
    "    alt=\"% Change in budget share\"\n",
    "  />\n",
    "  <figcaption style=\"font-style: italic\">\n",
    "    The change in the percent of total budget share for top 5 categories.\n",
    "  </figcaption>\n",
    "</div>\n",
    "\n",
    "This shows the actual percent change by year for the main 6 categories. With this chart it is easier to see that people began spending about 18% less on alcohol following the Great Recession, while they actually spent about 18% *more* on tobacco. It is also interesting to note the rapid increase in cost of education.\n",
    "\n",
    "Here are the two highest value categories comapred to each other:\n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    src=\"../assets/img/high-value.png\"\n",
    "    width=\"60%\"\n",
    "    style=\"border: 2px solid\"\n",
    "    alt=\"Main Spendingh\"\n",
    "  />\n",
    "  <figcaption style=\"font-style: italic\">\n",
    "    Housing and food expenditures\n",
    "  </figcaption>\n",
    "</div>\n",
    "\n",
    "And the lower value categories:\n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    src=\"../assets/img/low-value.png\"\n",
    "    width=\"60%\"\n",
    "    style=\"border: 2px solid\"\n",
    "    alt=\"Other Spending\"\n",
    "  />\n",
    "  <figcaption style=\"font-style: italic\">\n",
    "    Other Spending.\n",
    "  </figcaption>\n",
    "</div>\n",
    "\n",
    "The BLS also has data on employment information from this same time period. Looking at the columns for the change between 2007 and 2010, the Federal Government was the only sector to increase in employment, while all others lost between 1% and 28% of the workforce. \n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    src=\"../assets/img/blsemployment07.png\"\n",
    "    width=\"60%\"\n",
    "    style=\"border: 2px solid\"\n",
    "    alt=\"BLS Employment Statistics\"\n",
    "  />\n",
    "  <figcaption style=\"font-style: italic\">\n",
    "    Full chart available from the BLS website.\n",
    "  </figcaption>\n",
    "</div>\n",
    "\n",
    "Another source that is worth looking at is the data on Savings from the St. Louis government. \n",
    "<div align=\"center\">\n",
    "  <img\n",
    "    src=\"../assets/img/savings.png\"\n",
    "    width=\"60%\"\n",
    "    style=\"border: 2px solid\"\n",
    "    alt=\"Savings\"\n",
    "  />\n",
    "  <figcaption style=\"font-style: italic\">\n",
    "    Average savings of St. Louis residents.\n",
    "  </figcaption>\n",
    "</div>\n",
    "\n",
    "With this data we can understand a little more about the economic rebound in the later 2010s. It seems clear that as the workforce began to grow again from 2012-2020, people were able to put more of their money into savings. Looking back at our Percent Change graph, we also see that people have started spending less generally on everything except housing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0071ec-e97e-4fcc-893c-de44ca2c36d1",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Housing in America has been a persistently prominent issue for decades. Allowing too many people to apply for mortgage loans and buy property apparently created a significant amount of panic in the housing market, and they responded predatorily by jacking prices back up. Because of this, more people than ever before are renting without any sort of mortgage, and we are generally spending less on non-essential things like entertainment and alcohol. Additionally we see a trend of more money being diverted to savings, but with less mortgages and general spending, there is a question of what exactly the money is being saved for. \n",
    "\n",
    "There are some limitations to this data set. As mentioned in the main analysis, there is data included on demographics, but the range is very limited. Besides white, the only other options given were black or latino. Obviously this excludes a huge amount of other ethnicities and races, and in the end white people made up more than 80% of the reference group. There is also no information given regarding the regions surveyed. We do not know how much of this is representative of urban or suburban or even rural life. It is very possible that the number of people renting vs mortgaging looks extremely different between, say, New York City and a small town in Iowa. \n",
    "\n",
    "Still, there are obviously some trends in the data that speak for themselves. The average annual expenditures rose by about $2000 every year since 2010, and housing and education are the only categories whose share has not decreased. In fact, their budget share also seems to increase along with the total expenditures. This means that people have less and less money to spend on quality groceries, entertainment, and leisure activities. The desperate scramble for housing in the U.S is part of the reason we are so money-hungry; each year it costs more to have a roof over your head, causing great anxiety for multiple generations of Americans. Keeping money in savings so you aren't in danger of losing your home is a priority for almost everyone. More and more people are living with more and more roommates to try to keep their indivudal spending down. With the popularity of apps like Air B&B, the housing market is only growing more competitive. People are buying property with the sole intent of renting it out to someone else. This will keep driving up the demand for living spaces which will keep growing the cost, and so on and so forth. I believe that the housing bubble burst is a main factor driving this change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3319581-cdb7-4a46-bbf9-e7edeac30860",
   "metadata": {},
   "source": [
    "## Repository and Bibliography\n",
    "\n",
    "### Github Repository\n",
    "__[Here](https://github.com/bwarzel/research-project)__\n",
    "\n",
    "### Bibliography\n",
    "Original Main Data Set: https://www.bls.gov/opub/mlr/2014/article/consumer-spending-and-us-employment-from-the-recession-through-2022.htm\n",
    "Employment Statistics: https://www.bls.gov/opub/mlr/2014/article/consumer-spending-and-us-employment-from-the-recession-through-2022.htm\n",
    "St. Louis Savings: https://fred.stlouisfed.org/series/W398RC1A027NBEA\n",
    "2008 Consumer Spending Internal Report https://www.imf.org/external/pubs/ft/spn/2010/spn1001.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e30db80-eed6-446e-8c93-4c42983c583d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
